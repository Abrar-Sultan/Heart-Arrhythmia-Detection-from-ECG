{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, AveragePooling2D, BatchNormalization, Activation, Dense, Flatten, Dropout, LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics  import binary_crossentropy, categorical_crossentropy, mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta, SGD\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import efficientnet as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num of GPUs Availavle: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath('./')\n",
    "DATA_PATH = os.path.join('path', \"Beat_Images_(234x234)\")\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(DATA_PATH, 'Train')\n",
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(DATA_PATH, 'Test')\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(validation_split=0.1, rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batches = train_datagen.flow_from_directory(directory=train_path, \n",
    "                                            target_size=(234,234), \n",
    "                                            classes=['NOR', 'APC', 'FPNB', 'FVNB', 'LBB', 'PAB', 'PVC', 'RBB'], \n",
    "                                            batch_size=128,\n",
    "                                            subset='training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(train_batches.classes), \n",
    "            train_batches.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {\n",
    "    0: 0.17244932,\n",
    "    1: 4.36603881,\n",
    "    2: 33.5495614,\n",
    "    3: 13.52422207,\n",
    "    4: 1.90356858,\n",
    "    5: 2.97684465,\n",
    "    6: 2.01636968,\n",
    "    7: 1.95614259\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batches = train_datagen.flow_from_directory(directory=train_path, \n",
    "                                            target_size=(234,234), \n",
    "                                            classes=['NOR', 'APC', 'FPNB', 'FVNB', 'LBB', 'PAB', 'PVC', 'RBB'], \n",
    "                                            batch_size=128,\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = ImageDataGenerator(rescale=1. / 255).flow_from_directory(directory=test_path, \n",
    "                                                                        target_size=(234,234), \n",
    "                                                                        classes=['NOR', 'APC', 'FPNB', 'FVNB', 'LBB', 'PAB', 'PVC', 'RBB'], \n",
    "                                                                        batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotImages(images_arr):\n",
    "#     fig, axes = plt.subplots(1, 24, figsize=(20,20))\n",
    "#     axes = axes.flatten()\n",
    "#     for img, ax in zip( images_arr, axes):\n",
    "#         ax.imshow(img)\n",
    "#         ax.axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotImages(imgs)\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom Function to calculate F1 Score \n",
    "\n",
    "# def f1(y_true, y_pred):\n",
    "#     def recall(y_true, y_pred):\n",
    "#         \"\"\"Recall metric.\n",
    "\n",
    "#         Only computes a batch-wise average of recall.\n",
    "\n",
    "#         Computes the recall, a metric for multi-label classification of\n",
    "#         how many relevant items are selected.\n",
    "#         \"\"\"\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#         recall = true_positives / (possible_positives + K.epsilon())\n",
    "#         return recall\n",
    "\n",
    "#     def precision(y_true, y_pred):\n",
    "#         \"\"\"Precision metric.\n",
    "\n",
    "#         Only computes a batch-wise average of precision.\n",
    "\n",
    "#         Computes the precision, a metric for multi-label classification of\n",
    "#         how many selected items are relevant.\n",
    "#         \"\"\"\n",
    "#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#         predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#         precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#         return precision\n",
    "    \n",
    "#     precision = precision(y_true, y_pred)\n",
    "#     recall = recall(y_true, y_pred)\n",
    "    \n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'path\\\\best.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = ModelCheckpoint(filepath= checkpoint_filepath,  monitor=\"val_accuracy\", verbose=1, save_best_only=True, \n",
    "                            save_weights_only=True, mode=\"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(234, 234, 3)))\n",
    "# model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
    "model.add(Dense(8, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adadelta', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=100, class_weight=class_weights, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evalution\n",
    "score, acc = model.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x=test_batches, steps=len(test_batches))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_batches.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model.to_json()\n",
    "with open(\"path\\\\model_234x234_nvs_BN.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"path\\\\model_234x234_nvs_BN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(16, (3, 3), padding='same', activation = 'relu', input_shape=(234, 234, 3)))\n",
    "model_2.add(Conv2D(32, (3, 3), padding='same', activation = 'relu'))\n",
    "# model_2.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2, 2), strides= 2))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "model_2.add(Conv2D(64, (3, 3), padding='same', activation = 'relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model_2.add(MaxPool2D(pool_size=(2, 2), strides= 2))\n",
    "model_2.add(Dropout(0.5))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "\n",
    "model_2.add(Dense(144, activation='relu'))\n",
    "model_2.add(Dense(8, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer = 'sgd', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_2.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=100, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evalution\n",
    "score, acc = model_2.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "# print('Test F1 Score:', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_2.predict(x=test_batches, steps=len(test_batches))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_batches.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_2.to_json()\n",
    "with open(\"path\\\\model_2.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_2.save_weights(\"path\\\\model_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(16, (5, 5), padding='same', activation = 'relu', input_shape=(234, 234, 3)))\n",
    "model_3.add(Conv2D(32, (5, 5), padding='same', activation = 'relu'))\n",
    "# model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "model_3.add(Conv2D(64, (5, 5), padding='same', activation = 'relu'))\n",
    "model_3.add(Conv2D(64, (5, 5), padding='same', activation = 'relu'))\n",
    "# model_3.add(BatchNormalization())\n",
    "model_3.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model_3.add(Dropout(0.5))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "\n",
    "model_3.add(Dense(64, activation='relu'))\n",
    "model_3.add(Dense(64, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
    "\n",
    "model_3.add(Dense(8, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_3.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=20, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_3.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_3.predict(x=test_batches, steps=len(test_batches))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_batches.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_3.to_json()\n",
    "with open(\"path\\\\model_3.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_3.save_weights(\"path\\\\Saved Model\\\\model_3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv2D(8, (3, 3), padding='same', activation = 'relu', input_shape=(234, 234, 3)))\n",
    "model_4.add(Conv2D(16, (3, 3), padding='same', activation = 'relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Conv2D(32, (5, 5), padding='same', activation = 'relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Conv2D(64, (5, 5), padding='same', activation = 'relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Conv2D(64, (5, 5), padding='same', activation = 'relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(MaxPool2D(pool_size=(4, 4), padding='same'))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "\n",
    "model_4.add(Dense(64, activation='relu'))\n",
    "model_4.add(Dense(64, activation='relu',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
    "\n",
    "model_4.add(LeakyReLU(alpha=0.1))\n",
    "model_4.add(Dense(8, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_4.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=100, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_4.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_4.predict(x=test_batches, steps=len(test_batches))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_batches.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_4.to_json()\n",
    "with open(\"path\\\\model_4.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_4.save_weights(\"path\\\\model_4.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model 5 (from paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(Conv2D(8, (5, 11), strides=1, padding='same', activation = 'relu', input_shape=(234, 234, 3)))\n",
    "model_5.add(Conv2D(16, (5, 11), strides=1, padding='same', activation = 'relu'))\n",
    "model_5.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "\n",
    "model_5.add(Dense(144, activation='relu'))\n",
    "model_5.add(Dense(8, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(optimizer = 'adadelta', loss = 'mean_squared_error', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_5.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=50, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_5.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_5.predict(x=test_batches, steps=len(test_batches))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=-1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_batches.classes, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_5.to_json()\n",
    "with open(\"path\\\\model_5.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_5.save_weights(\"path\\\\model_5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MESO4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(8, (3, 3), padding='same', activation = 'relu', input_shape=(234, 234, 3)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "\n",
    "model_1.add(Conv2D(8, (5, 5), padding='same', activation = 'relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_1.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "model_1.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPool2D(pool_size=(4, 4), padding='same'))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "\n",
    "model_1.add(Dropout(0.5))\n",
    "\n",
    "model_1.add(Dense(16))\n",
    "model_1.add(LeakyReLU(alpha=0.1))\n",
    "\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_1.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=50, class_weight=class_weights, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score, acc = model_1.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(234,234,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_vgg16.layers:\n",
    "    base_model_vgg16.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model_vgg16.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = Sequential()\n",
    "model_vgg16.add(base_model_vgg16)\n",
    "model_vgg16.add(Flatten())\n",
    "model_vgg16.add(Dense(144, activation = 'relu'))\n",
    "model_vgg16.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_vgg16.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=20, class_weight=class_weights, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc, f1 = model_vgg16.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "print('F1 score: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_vgg16.to_json()\n",
    "with open(\"path\\\\model_vgg16.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_vgg16.save_weights(\"path\\\\model_vgg16.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(234,234,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_vgg19.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_vgg19.layers:\n",
    "    base_model_vgg19.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model_vgg19.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19 = Sequential()\n",
    "model_vgg19.add(base_model_vgg19)\n",
    "model_vgg19.add(Flatten())\n",
    "model_vgg19.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg19.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_vgg19.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=20, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_vgg19.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INCEPTION V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_inceptionv3 = InceptionV3(weights=None, include_top=False, input_shape=(234,234,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_inceptionv3.layers:\n",
    "    base_model_inceptionv3.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, layer in enumerate(base_model_inceptionv3.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionv3 = Sequential()\n",
    "model_inceptionv3.add(base_model_inceptionv3)\n",
    "model_inceptionv3.add(Flatten())\n",
    "model_inceptionv3.add(Dense(64, activation = 'relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),activity_regularizer=regularizers.l2(1e-5)))\n",
    "model_inceptionv3.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionv3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_inceptionv3.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=25, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_inceptionv3.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_inceptionv3.to_json()\n",
    "with open(\"path\\\\model_inceptionv3.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_inceptionv3.save_weights(\"path\\\\model_inceptionv3.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_efficientnet = efn.EfficientNetB0(weights='imagenet',include_top=False,pooling='max',input_shape=(234, 234, 3))\n",
    "base_model_efficientnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_efficientnet.layers:\n",
    "    base_model_efficientnet.trainable = True\n",
    "    \n",
    "for i, layer in enumerate(base_model_efficientnet.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnet = Sequential()\n",
    "model_efficientnet.add(base_model_efficientnet)\n",
    "model_efficientnet.add(Flatten())\n",
    "model_efficientnet.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnet.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_efficientnet.fit(x=train_batches, steps_per_epoch=len(train_batches), validation_data=validation_batches,\n",
    "           validation_steps=len(validation_batches), epochs=25, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Curve\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val accuracy')\n",
    "plt.xlabel('Ephocs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model_efficientnet.evaluate(x=test_batches, steps=len(test_batches))\n",
    "\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "\n",
    "fer_json = model_efficientnet.to_json()\n",
    "with open(\"path\\\\model_efficientnet.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model_efficientnet.save_weights(\"path\\\\model_efficientnet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confution Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_confusion_matrix(cm, classes,\n",
    "#                           normalize=False,\n",
    "#                           title='Confusion matrix',\n",
    "#                           cmap=plt.cm.Blues):\n",
    "#     \"\"\"\n",
    "#     This function prints and plots the confusion matrix.\n",
    "#     Normalization can be applied by setting `normalize=True`.\n",
    "#     \"\"\"\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "#     tick_marks = np.arange(len(classes))\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\n",
    "#     plt.yticks(tick_marks, classes)\n",
    "\n",
    "#     if normalize:\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "#     else:\n",
    "#         print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "#         plt.text(j, i, cm[i, j],\n",
    "#             horizontalalignment=\"center\",\n",
    "#             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_batches.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm_plot_labels = ['PB','L']\n",
    "# plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = glob.glob('Image _for_Prediction/*.png')\n",
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_perdiction_on_bb(img):\n",
    "    test_image = image.load_img(img, target_size =(234,234))\n",
    "    plt.imshow(test_image)\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = model.predict(test_image) \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    beat = ['LBB', 'FPNB']\n",
    "    result_in_number = [result[0][0],result[0][1]]\n",
    "    ax.bar(beat,result_in_number)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in test_img:\n",
    "    make_perdiction_on_bb(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img = os.path.join(test_path, 'FPNB', '4.png')\n",
    "# test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image = image.load_img(test_img, target_size =(234,234))\n",
    "# test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image = image.load_img(test_img, target_size =(234,234))\n",
    "# #test_image = image.load_img('path', target_size =(128,192))\n",
    "# plt.imshow(test_image)\n",
    "# test_image = image.img_to_array(test_image)\n",
    "# test_image = np.expand_dims(test_image, axis = 0)\n",
    "# result = model.predict(test_image) \n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_axes([0,0,1,1])\n",
    "# beat = ['LBB', 'FPNB']\n",
    "# result_in_number = [result[0][0],result[0][1]]\n",
    "# ax.bar(beat,result_in_number)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(x=test_batches, steps=len(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_from_json(open(\"path\\\\model_234x234.json\", \"r\").read())\n",
    "# model.load_weights('path\\\\model_234x234.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
